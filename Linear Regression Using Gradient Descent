import numpy as np

def linear_regression_gradient_descent(X: np.ndarray, y: np.ndarray, alpha: float, iterations: int) -> np.ndarray:
    m, n = X.shape  # m = number of training examples, n = number of features
    theta = np.zeros((n, 1))  # Initialize theta (parameters) as zeros (shape: n, 1)

    for i in range(iterations):  # Repeat for the given number of iterations
        # Forward pass: Calculate the predicted values (hypothesis)
        z = X @ theta  # z = (m, 1) - predicted values for each example

        # Loss: Find the difference between predicted and actual values
        # We reshape y to (m, 1) to ensure it matches the shape of z for subtraction
        loss = z - y.reshape(-1, 1)  # loss = (m, 1) - difference between predicted and actual

        # Gradient: Compute the gradient of the cost function
        # We use the formula (1/m) * X.T @ loss to calculate the gradient
        gradient = (1 / m) * X.T @ loss  # gradient = (n, 1)

        # Update the parameters (theta) using the gradient descent rule
        theta = theta - alpha * gradient  # theta = theta - (learning rate * gradient)

    return theta  # Return the learned parameters (theta)
