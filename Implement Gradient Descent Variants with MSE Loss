import numpy as np

def gradient_descent(X, y, weights, learning_rate, n_iterations, batch_size=1, method='batch'):

	if method == 'batch':
        for epoch in range(n_iterations):
            predictions = X @ weights                # Predictions for all samples
            error = predictions - y                  # Vector of errors
            gradient = (2 / len(X)) * (X.T @ error)  # Gradient of MSE
            weights -= learning_rate * gradient      # Update weights
        return weights
	
	elif method == 'mini_batch':
		for epoch in range(n_iterations):
            for start_index in range(0, len(X), batch_size):
                X_batch = X[start_index : start_index + batch_size]
                y_batch = y[start_index : start_index + batch_size]
                
                predictions = X_batch @ weights
                error = predictions - y_batch
                
                gradient = (2 / batch_size) * (X_batch.T @ error)
                weights -= learning_rate * gradient
                
        return weights
	
	else:
		for epoch in range(n_iterations):
            for index in range(len(X)):
                x_sample = X[index : index + 1]       # Single input sample
                y_sample = y[index : index + 1]       # Corresponding target
                prediction = x_sample @ weights       # Prediction
                error = prediction - y_sample         # Error
                gradient = 2 * (x_sample.T @ error)   # Gradient of MSE
                weights -= learning_rate * gradient   # Update weights
        return weights
			
